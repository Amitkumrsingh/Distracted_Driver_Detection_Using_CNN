{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTING THE LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_files\n",
    "from keras.utils import np_utils\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.preprocessing import image                  \n",
    "from tqdm import tqdm\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph Adjustments\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is OS\n",
      " Volume Serial Number is 4659-C57D\n",
      "\n",
      " Directory of C:\\Users\\amitk\\Desktop\n",
      "\n",
      "27-01-2023  02:12    <DIR>          .\n",
      "27-01-2023  00:11    <DIR>          ..\n",
      "27-01-2023  00:05    <DIR>          .ipynb_checkpoints\n",
      "26-01-2023  19:56             1,038 04. Data Structures (Advanced) - Shortcut.lnk\n",
      "24-01-2023  17:17            42,973 Amit Kumar Singh_Resume.docx\n",
      "10-10-2022  18:05           108,175 Amit Kumar Singh_Resume.pdf\n",
      "04-08-2022  22:53    <DIR>          Coding blocks\n",
      "27-01-2023  01:25    <DIR>          csv_files\n",
      "21-10-2022  01:03               830 DBMS - Shortcut.lnk\n",
      "27-01-2023  02:12            19,255 Distracted Driver Detection .ipynb\n",
      "27-01-2023  01:11    <DIR>          imgs\n",
      "21-11-2022  20:25         1,727,620 Linux_terminal_command_Cheatsheet.pdf\n",
      "26-01-2023  20:00               894 Live Classes - Shortcut.lnk\n",
      "20-10-2022  01:14    <DIR>          Love Babbar Data Structures and Algorithms Notes\n",
      "18-01-2023  21:52    <DIR>          Low level design\n",
      "14-11-2021  15:49               926 Machine learning - Shortcut.lnk\n",
      "27-01-2023  00:11    <DIR>          model\n",
      "05-10-2022  11:14             1,443 Modern JavaScript From The Beginning - Shortcut.lnk\n",
      "20-10-2022  01:15             1,658 Namaste javascript - Shortcut.lnk\n",
      "21-10-2022  00:55               814 OS - Shortcut.lnk\n",
      "27-01-2023  01:25    <DIR>          pickle_files\n",
      "06-06-2021  11:38           105,366 Placement calander!.pdf\n",
      "21-10-2022  00:56               869 SDE Sheet - Shortcut.lnk\n",
      "27-01-2023  01:24    <DIR>          state-farm-distracted-driver-detection\n",
      "16-12-2019  04:23     4,296,022,692 state-farm-distracted-driver-detection.zip\n",
      "              14 File(s)  4,298,034,553 bytes\n",
      "              11 Dir(s)  18,601,951,232 bytes free\n"
     ]
    }
   ],
   "source": [
    "# Current Directory\n",
    "!dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the train,test and model directories\n",
    "\n",
    "We will create the directories for train,test and model training paths if not present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DIR = os.path.join(os.getcwd(),\"imgs\",\"test\")\n",
    "TRAIN_DIR = os.path.join(os.getcwd(),\"imgs\",\"train\")\n",
    "MODEL_PATH = os.path.join(os.getcwd(),\"model\",\"self_trained\")\n",
    "PICKLE_DIR = os.path.join(os.getcwd(),\"pickle_files\")\n",
    "CSV_DIR = os.path.join(os.getcwd(),\"csv_files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(TEST_DIR):\n",
    "    print(\"Testing data does not exists\")\n",
    "if not os.path.exists(TRAIN_DIR):\n",
    "    print(\"Training data does not exists\")\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    print(\"Model path does not exists\")\n",
    "    os.makedirs(MODEL_PATH)\n",
    "    print(\"Model path created\")\n",
    "if not os.path.exists(PICKLE_DIR):\n",
    "    os.makedirs(PICKLE_DIR)\n",
    "if not os.path.exists(CSV_DIR):\n",
    "    os.makedirs(CSV_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a csv file having the location of the files present for training and test images and their associated class if present so that it is easily traceable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_csv(DATA_DIR,filename):\n",
    "    class_names = os.listdir(DATA_DIR)\n",
    "    data = list()\n",
    "    if(os.path.isdir(os.path.join(DATA_DIR,class_names[0]))):\n",
    "        for class_name in class_names:\n",
    "            file_names = os.listdir(os.path.join(DATA_DIR,class_name))\n",
    "            for file in file_names:\n",
    "                data.append({\n",
    "                    \"Filename\":os.path.join(DATA_DIR,class_name,file),\n",
    "                    \"ClassName\":class_name\n",
    "                })\n",
    "    else:\n",
    "        class_name = \"test\"\n",
    "        file_names = os.listdir(DATA_DIR)\n",
    "        for file in file_names:\n",
    "            data.append(({\n",
    "                \"FileName\":os.path.join(DATA_DIR,file),\n",
    "                \"ClassName\":class_name\n",
    "            }))\n",
    "    data = pd.DataFrame(data)\n",
    "    data.to_csv(os.path.join(os.getcwd(),\"csv_files\",filename),index=False)\n",
    "\n",
    "create_csv(TRAIN_DIR,\"train.csv\")\n",
    "create_csv(TEST_DIR,\"test.csv\")\n",
    "data_train = pd.read_csv(os.path.join(os.getcwd(),\"csv_files\",\"train.csv\"))\n",
    "data_test = pd.read_csv(os.path.join(os.getcwd(),\"csv_files\",\"test.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22424 entries, 0 to 22423\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Filename   22424 non-null  object\n",
      " 1   ClassName  22424 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 350.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c0    2489\n",
       "c3    2346\n",
       "c4    2326\n",
       "c6    2325\n",
       "c2    2317\n",
       "c5    2312\n",
       "c1    2267\n",
       "c9    2129\n",
       "c7    2002\n",
       "c8    1911\n",
       "Name: ClassName, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train['ClassName'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>ClassName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>22424</td>\n",
       "      <td>22424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>22424</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>C:\\Users\\amitk\\Desktop\\imgs\\train\\c0\\img_10002...</td>\n",
       "      <td>c0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>2489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Filename ClassName\n",
       "count                                               22424     22424\n",
       "unique                                              22424        10\n",
       "top     C:\\Users\\amitk\\Desktop\\imgs\\train\\c0\\img_10002...        c0\n",
       "freq                                                    1      2489"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "nf = data_train['ClassName'].value_counts(sort=False)\n",
    "labels = data_train['ClassName'].value_counts(sort=False).index.tolist()\n",
    "y = np.array(nf)\n",
    "width = 1/1.5\n",
    "N = len(y)\n",
    "x = range(N)\n",
    "\n",
    "fig = plt.figure(figsize=(20,15))\n",
    "ay = fig.add_subplot(211)\n",
    "\n",
    "plt.xticks(x, labels, size=15)\n",
    "plt.yticks(size=15)\n",
    "\n",
    "ay.bar(x, y, width, color=\"blue\")\n",
    "\n",
    "plt.title('Bar Chart',size=25)\n",
    "plt.xlabel('classname',size=15)\n",
    "plt.ylabel('Count',size=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileName</th>\n",
       "      <th>ClassName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\amitk\\Desktop\\imgs\\test\\img_1.jpg</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\amitk\\Desktop\\imgs\\test\\img_10.jpg</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\amitk\\Desktop\\imgs\\test\\img_100.jpg</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\amitk\\Desktop\\imgs\\test\\img_1000.jpg</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\amitk\\Desktop\\imgs\\test\\img_100000.jpg</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          FileName ClassName\n",
       "0       C:\\Users\\amitk\\Desktop\\imgs\\test\\img_1.jpg      test\n",
       "1      C:\\Users\\amitk\\Desktop\\imgs\\test\\img_10.jpg      test\n",
       "2     C:\\Users\\amitk\\Desktop\\imgs\\test\\img_100.jpg      test\n",
       "3    C:\\Users\\amitk\\Desktop\\imgs\\test\\img_1000.jpg      test\n",
       "4  C:\\Users\\amitk\\Desktop\\imgs\\test\\img_100000.jpg      test"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79726, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation:\n",
    "1. There are total 22424 training samples\n",
    "2. There are total 79726 testing samples\n",
    "3. The training dataset is equally balanced to a great extent and hence we need not do any downsampling of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting into numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'c7': 0, 'c6': 1, 'c0': 2, 'c4': 3, 'c3': 4, 'c2': 5, 'c1': 6, 'c5': 7, 'c8': 8, 'c9': 9}\n"
     ]
    }
   ],
   "source": [
    "labels_list = list(set(data_train['ClassName'].values.tolist()))\n",
    "labels_id = {label_name:id for id,label_name in enumerate(labels_list)}\n",
    "print(labels_id)\n",
    "data_train['ClassName'].replace(labels_id,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(os.getcwd(),\"pickle_files\",\"labels_list.pkl\"),\"wb\") as handle:\n",
    "    pickle.dump(labels_id,handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22424, 10)\n"
     ]
    }
   ],
   "source": [
    "labels = to_categorical(data_train['ClassName'])\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting into Train and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xtrain,xtest,ytrain,ytest = train_test_split(data_train.iloc[:,0],labels,test_size = 0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting into 64*64 images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(128, 128))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 17939/17939 [00:44<00:00, 402.54it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from PIL import ImageFile                            \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True                 \n",
    "\n",
    "# pre-process the data for Keras\n",
    "train_tensors = paths_to_tensor(xtrain).astype('float32')/255 - 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 4485/4485 [00:12<00:00, 349.20it/s]\n"
     ]
    }
   ],
   "source": [
    "valid_tensors = paths_to_tensor(xtest).astype('float32')/255 - 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "##takes too much ram \n",
    "## run this if your ram is greater than 16gb \n",
    "# test_tensors = paths_to_tensor(data_test.iloc[:,0]).astype('float32')/255 - 0.5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 128, 128, 64)      832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 128)       32896     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 256)       131328    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 512)       524800    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 500)               16384500  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5010      \n",
      "=================================================================\n",
      "Total params: 17,079,366\n",
      "Trainable params: 17,079,366\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(128,128,3), kernel_initializer='glorot_normal'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=128, kernel_size=2, padding='same', activation='relu', kernel_initializer='glorot_normal'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=256, kernel_size=2, padding='same', activation='relu', kernel_initializer='glorot_normal'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=512, kernel_size=2, padding='same', activation='relu', kernel_initializer='glorot_normal'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500, activation='relu', kernel_initializer='glorot_normal'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax', kernel_initializer='glorot_normal'))\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "plot_model(model,to_file=os.path.join(MODEL_PATH,\"model_distracted_driver.png\"),show_shapes=True,show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "filepath = os.path.join(MODEL_PATH,\"distracted-{epoch:02d}-{val_accuracy:.2f}.hdf5\")\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max',period=1)\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_history = model.fit(train_tensors,ytrain,validation_data = (valid_tensors, ytest),epochs=25, batch_size=40, shuffle=True,callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\n",
    "ax1.plot(model_history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax1.plot(model_history.history['val_loss'], color='r', label=\"validation loss\")\n",
    "ax1.set_xticks(np.arange(1, 25, 1))\n",
    "ax1.set_yticks(np.arange(0, 1, 0.1))\n",
    "\n",
    "ax2.plot(model_history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "ax2.plot(model_history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "ax2.set_xticks(np.arange(1, 25, 1))\n",
    "\n",
    "legend = plt.legend(loc='best', shadow=True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Analysis\n",
    "\n",
    "Finding the Confusion matrix,Precision,Recall and F1 score to analyse the model thus created "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=14):\n",
    "    df_cm = pd.DataFrame(\n",
    "        confusion_matrix, index=class_names, columns=class_names, \n",
    "    )\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    fig.savefig(os.path.join(MODEL_PATH,\"confusion_matrix.png\"))\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_heatmap(n_labels, n_predictions, class_names):\n",
    "    labels = n_labels #sess.run(tf.argmax(n_labels, 1))\n",
    "    predictions = n_predictions #sess.run(tf.argmax(n_predictions, 1))\n",
    "\n",
    "#     confusion_matrix = sess.run(tf.contrib.metrics.confusion_matrix(labels, predictions))\n",
    "    matrix = confusion_matrix(labels.argmax(axis=1),predictions.argmax(axis=1))\n",
    "    row_sum = np.sum(matrix, axis = 1)\n",
    "    w, h = matrix.shape\n",
    "\n",
    "    c_m = np.zeros((w, h))\n",
    "\n",
    "    for i in range(h):\n",
    "        c_m[i] = matrix[i] * 100 / row_sum[i]\n",
    "\n",
    "    c = c_m.astype(dtype = np.uint8)\n",
    "\n",
    "    \n",
    "    heatmap = print_confusion_matrix(c, class_names, figsize=(18,10), fontsize=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = list()\n",
    "for name,idx in labels_id.items():\n",
    "    class_names.append(name)\n",
    "# print(class_names)\n",
    "ypred = model.predict(valid_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_heatmap(ytest,ypred,class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision Recall F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred_class = np.argmax(ypred,axis=1)\n",
    "# print(ypred_class[:10])\n",
    "ytest = np.argmax(ytest,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(ytest,ypred_class)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(ytest, ypred_class,average='weighted')\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(ytest,ypred_class,average='weighted')\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(ytest,ypred_class,average='weighted')\n",
    "print('F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "868d404319e13d0489368dc96af563abd21c075bcffa60b4127138386b1d31fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
